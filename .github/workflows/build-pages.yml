name: Build and Deploy HTML (GitHub Pages)

on:
  workflow_run:
    workflows: ["Build and Upload PDFs"]
    types: [completed]
  workflow_dispatch: 

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  build-html:
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success' }}
    environment:
      name: github-pages

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y pandoc jq

      - name: Download all PDF Artifacts
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: build-pdf.yml
          run_id: ${{ github.event.workflow_run.id }}
          path: all-pdfs
          search_artifacts: true 

      - name: Convert LaTeX to HTML and Integrate PDFs
        run: |
          mkdir -p html
          touch html/.nojekyll
          cp style.css html/style.css

          ROOT_DIR=$(pwd)
          BIB_PATH="$ROOT_DIR/papers/references.bib"
          INDEX_FILE="$ROOT_DIR/html/index.html"

          # --- Start index ---
          PROJECT_TITLE=$(jq -r '.title' papers.json)
          echo "<html><head><title>$PROJECT_TITLE</title>" \
               "<meta name='color-scheme' content='light dark'>" \
               "<link rel='stylesheet' href='style.css'></head>" \
               "<body class='bodytext'><h1>$PROJECT_TITLE</h1>" \
               > "$INDEX_FILE"

          # --- Recursive function to process items ---
          generate_list() {
            local parent_path=$1
            local items_json=$2
            echo "<ul>"
            echo "$items_json" | jq -c '.[]' | while read -r item; do
              title=$(echo "$item" | jq -r '.title')
              slug=$(echo "$item" | jq -r '.slug')
              full_path="$parent_path/$slug"

              html_dir="$ROOT_DIR/html/$full_path"
              mkdir -p "$html_dir"

              # Copy PDF if exists
              PDF_FILE=$(find all-pdfs/pdf-* -type f -name "*$slug*.pdf" | head -n1)
              PDF_LINK=""
              [ -n "$PDF_FILE" ] && PDF_LINK=" | <a href='./$(basename "$PDF_FILE")'>[PDF]</a>"
              [ -n "$PDF_FILE" ] && cp "$PDF_FILE" "$html_dir/"

              # Convert all tex files in this directory
              TEX_DIR="$ROOT_DIR/papers/$full_path"
              if [ -d "$TEX_DIR" ]; then
                find "$TEX_DIR" -name "*.tex" ! -name "common.tex" ! -name "glossary.tex" | while read -r tex; do
                  base=$(basename "$tex" .tex)
                  out="$html_dir/index.html"
                  css_rel=$(realpath --relative-to="$html_dir" "$ROOT_DIR/style.css")
                  [ -d "$TEX_DIR/figures" ] && cp -r "$TEX_DIR/figures" "$html_dir/"
                  (cd "$(dirname "$tex")" && \
                    pandoc "$(basename "$tex")" -s -M ishtml=true --from=latex --to=html5 \
                    --citeproc --bibliography="$BIB_PATH" -c "$css_rel" -o "$out") || exit 1
                done
              fi

              # Print item link in index
              echo "<li><a href='./$full_path/'>$title</a>$PDF_LINK"

              # Recursively process children
              has_children=$(echo "$item" | jq '.children | length // 0')
              if [ "$has_children" -gt 0 ]; then
                children=$(echo "$item" | jq -c '.children')
                generate_list "$full_path" "$children"
              fi

              echo "</li>"
            done
            echo "</ul>"
          }

          # --- Loop over sections ---
          jq -c '.sections[]' papers.json | while read -r section; do
            section_title=$(echo "$section" | jq -r '.title')
            echo "<h2>$section_title</h2>" >> "$INDEX_FILE"
            items=$(echo "$section" | jq -c '.items')
            generate_list "" "$items" >> "$INDEX_FILE"
          done

          echo "</body></html>" >> "$INDEX_FILE"
