\chapter{Introduction}

\section{The Elusive Theory of Everything}

Various approaches, including string theory, loop quantum gravity, and others, are currently under active exploration. 
Nevertheless, consensus on the correct approach, or even whether any of them will ultimately yield a comprehensive theory, remains elusive.

Some scientists have begun to question the very 
notion of a ``Theory of Everything.'' According to Hawking~\cite{hawking1988brief}, our unique position as observers within the universe 
raises concerns about our ability to describe a system of which we are an intrinsic part. Gödel's incompleteness theorem~\cite{godel1931} 
suggests that any self-referential system, such as a Theory of Everything seeking to encompass the universe, must inevitably contend with 
either incompleteness or inconsistency. This implies that certain inquiries will perpetually elude the theory, or contradictions may remain irreconcilable.

Moreover, a theory cannot genuinely be deemed a ``Theory of Everything'' without addressing the intricacies of human behavior. 
Thus far, physics has fallen short in providing equations governing all aspects of human conduct.
Pain does not appear in Einstein’s stress-energy tensor. The Standard Model has no particle for consciousness. 

According to Penrose~\cite{penrose1994shadows}, the operation of the human brain might not an axiomatic system. Gödel's incompleteness theorem 
states that within complex axiomatic systems, there exist true statements that cannot be proven true or false. Since computers and Turing 
Machines are equivalent to axiomatic systems, there must be answers that cannot be obtained using these machines. However, 
Penrose speculates that the human brain can arrive at such answers, indicating that we are not merely computational machines.

Even if physics were to produce a unified theory some day, would it truly answer the most profound questions? 
Would it explain what matter and energy actually are—not just how they behave? 
Where did all the matter and energy come from? What is the nature of pain, consciousness, and the human experience?


\section{A Database Software}

One can easily imagine a powerful computer with a huge database and advanced logic. 
Such a system could be highly efficient in its operations, capable of making accurate and intelligent decisions in nearly any imaginable situation. 
However, it is difficult to see how such a mechanically operating machine could truly feel pain.

Imagine a typical software program consisting of thousands of lines of code. How many additional source lines would need to be added to 
transform the software into a conscious entity? Would it be the 1014th line that suddenly imbues the system with the ability to feel pain? 
Could it be the introduction of a deeply nested loop that finally grants consciousness? Or is it the number of \texttt{if/else} clauses that holds the secret?

Regardless of the number of loops and source lines added, it appears that nothing significant would occur. 
The software program would remain just that---a software program, albeit larger in size.

Neuroscience has made significant advances in studying the operation of the human brain. The introduction of brain imaging techniques, 
such as magnetic resonance imaging (MRI), allows researchers to examine the neurobiological correlates of human behaviors. 
What is remarkable is that human behaviors do not seem reducible to the mere operation of brain cells. 
It seems conscious behaviors cannot be explained solely through the physical processes of the brain. 
This is known as the ``hard problem of consciousness''~\cite{chalmers1995facing}.

Unlike the human brain, a computer is a mechanical device whose operation can be reduced to the manipulation of its bits and pieces. 
The elementary building blocks of the computer are typically electronic components equivalent to mechanical relays. 
The notion that a collection of relays connected in a network of copper wires could genuinely experience consciousness and perceive 
pain is somewhat difficult to believe. Should I type gently on my keyboard, fearing that striking the keys too hard might trigger a migraine 
for my laptop? Do partially broken memory chips introduce suffering, much like a broken tooth does for its owner? 
Could defects transform my happy computer into a suffering one, making it wish it were dead, or at least turned off?

If computers were truly capable of sensing pain, what would be the worst thing that could happen to a piece of software? 
Is it division by zero, or a reference to an uninitialized variable?

\begin{lstlisting}[language=C, caption={A humorous view on software pain}]
int uninitialized;
int initialized = 3;

int good = 2 * PI * initialized;   // feel good :)
int bad  = 2 * PI * uninitialized; // feel pain :(
\end{lstlisting}

If consciousness is not solely a software issue, could it be related to hardware instead? For example, the graphics board controls what the 
computer renders on its screen. By writing appropriate values to memory addresses constituting the so-called video memory, one can turn pixels 
on and off to create images. What would be the memory addresses one has to poke in order to create pain?

\begin{lstlisting}[language=C, caption={Attempting to ``poke'' pain into memory}]
*((bool *)0x000000) = true; // argh
\end{lstlisting}

As ridiculous as these examples may be, they demonstrate the problem well. There is not even a hint of understanding of how pain 
and other human experiences could be implemented with software and traditional computers.

Could consciousness lurk in the fact that humans are composed of organic biological tissue---which is considered ``alive''---as opposed to 
non-organic matter like silicon? Both fat and silicon are ultimately made up of the very same type of subcomponents. 
It would be like arguing that if you pile Legos one way, they become alive, and by piling them another way, they become non-organic, dead material.

Is all matter conscious to some degree, as panpsychism suggests? Could plants, trees, or even rocks have some level of 
consciousness? \cite{Goff2019,Strawson2006,Chalmers2015,Whitehead1929}

The best imaginable way to study whether an object is conscious is by torturing it with an appropriate torturing device. 
So let us torture rocks with the best possible rock-torturing device one can imagine---a sledgehammer. 
Rocks do not seem to care! This observation cannot, of course, prove rocks unconscious. Rocks could well be conscious, 
they just do not have the sense to feel pain. Or perhaps they do sense pain intensely, but they just cannot show it. 
They might be in everlasting pain, but have no mouth to scream, no legs to kick. What a terrible destiny!

Anyway, if Penrose~\cite{penrose1994shadows} is right and consciousness is not an axiomatic system, then what else is there?
Must we look beyond science for answers? Or is it possible that we already know enough to draw the right conclusions?





\section{Methodological Epilogue}

At the heart of this method lies the idea that we are embedded within the very system we seek to understand. 
Any attempt to grasp the deep nature of reality is therefore subject to the same self-referential limitations 
revealed by Gödel's incompleteness theorems. Just as no formal system can fully account for its own consistency, 
no observer within the universe can fully explain the universe from the inside.

However, if we—the observers—can be simulated as a subset of the system, then we can externalize the entire question. 
By encoding physical and experiential phenomena in a simulation, we relocate them to a computational substrate 
that is externally observable. We can then examine the simulation from the "outside," free 
from the blind spots imposed by internal self-reference.


The method is operationally simple:

\begin{itemize}
    \item Construct a simulation that captures the essential features of the phenomenon to be studied.
    \item Run the simulation and extract its execution trace—the full sequence of internal states—capturing all the information in the simulation.
    \item Study the informational structure of this trace. What ever it is that we study must 
    emerge from the computer running the simulation. So it should be present in the trace.
\end{itemize}

This approach enables rigorous analysis of systems that appear mysterious from the inside by translating the 
problem into a domain where self-reference no longer impairs insight—namely, to a system whose operation we 
fully understand: the computer.