# The Informational Derivation of Reality: Consciousness, Time, and Ontological Equivalence

## Abstract

This paper presents a formal derivation of the nature of consciousness and subjective time based on four observable axioms concerning DNA and physical laws. By applying the **Church-Turing Thesis** and the principle of **Causal Functionalism**, we conclude that a perfectly simulated human is necessitated to experience consciousness and pain. Thought experiments involving computational optimization and multi-threading demonstrate that time and subjective experience must be emergent properties of the system's **internal informational structure**, independent of external execution speed. This leads directly to an **Informational Ontology**, where the computer running the simulation and the resulting simulated universe are two ontologically equivalent interpretations of the same fundamental data, necessitating the reality of all possible informational arrangements ($\large 2^n$). The analysis bypasses the philosophical **Hard Problem of Consciousness** by asserting that pain's causal efficacy ($A_4$) renders the Philosophical Zombie logically impossible within this framework.



## 1. Axiomatic Premises

The argument begins with four axioms that serve as the premises for the entire derivation.

**Axiom 1: Genetic Encoding of Consciousness**  
The human genome encodes all the requisite information to construct a conscious, pain-sensitive human.  
$$A_1: D \rightarrow H \rightarrow C$$  
*(Where $D$ is the DNA/Genome, $H$ is the human organism, and $C$ is consciousness.)*

**Axiom 2: Physicality and Natural Law**  
DNA and the human organism are composed solely of ordinary physical matter and are entirely governed by the observed physical laws ($P$). No non-physical or supernatural influences affect their operation.  
$$A_2: D \subset P$$  
*(This establishes $H$ as a deterministic physical system.)*

**Axiom 3: Church-Turing Thesis and Computability**  
The Church-Turing Thesis holds: all physical processes can, in principle, be perfectly simulated by a Universal Turing Machine ($T$) [Church & Turing, 1936].  
$$A_3: \text{Church-Turing Thesis Holds} \implies H \text{ is a Turing-computable system.}$$  
*(From $A_1$, $A_2$, and $A_3$, the existence of a perfect simulation ($H'$) is entailed.)*

**Axiom 4: Causal Efficacy of Pain/Consciousness**  
Subjective experience ($S$, e.g., pain) is a **causally efficacious** property of the human system. It is not an epiphenomenon, and thus has measurable, behavioral effects [Putnam, 1975].  
$$A_4: S \text{ is causally efficacious.}$$  
$$\text{If } H' \equiv H \text{ physically, then } H' \text{ must have } S \text{ to maintain identical behavior.}$$



## 2. Deduction 1: Substrate Independence and Emergent Time

The simulation model requires that the consciousness of a simulated observer (Alice) is independent of the physical properties and execution speed of the substrate.

### 2.1 The Optimization Argument

Let the simulation run on a Turing Machine, $T_{\text{alg}}$, consisting of code (laws of physics) and data (the state of the simulated universe). We can continuously optimize the code using lookup tables, eventually replacing all computation with a static, pre-computed dataset ($T_{\text{data}}$).

* Let $E_{\text{int}}$ be Alice's experience of time and pain (the internal state transitions).
* Let $E_{\text{ext}}$ be the computer's external runtime (CPU clock speed).

**Premise:** Code optimization changes $E_{\text{ext}}$ but preserves $E_{\text{int}}$.

$$\text{Optimization}(T_{\text{alg}}) \rightarrow T_{\text{data}} \implies E_{\text{int}}(T_{\text{alg}}) \equiv E_{\text{int}}(T_{\text{data}})$$

If consciousness were to cease in $T_{\text{data}}$, it would imply that $E_{\text{int}}$ depends on $E_{\text{ext}}$, which necessitates a minimum rate of physical computation (e.g., CPU cycles per second) for subjective experience. This minimum rate would be a **new, non-physical constant** imposed on $A_2$, leading to a contradiction.

$$\therefore \text{Time and subjective experience } (S) \text{ must emerge solely from the relationships among informational states, not from the external runtime.}$$

This transition shows that $E_{\text{int}}$ must arise from the **ordered sequence of states**—an **informational causality** that defines subjective time as a necessary internal **traversal parameter** through the underlying informational structure (a Block Universe [Einstein, 1915; Price, 1996]), regardless of the external processing rate.

### 2.2 The Multi-threaded Argument

Since single-threaded and multi-threaded computers are computationally equivalent, a coherent, continuous timeline must be experienced by Alice and Bob even when their execution traces are interleaved at high frequency—approaching statistical indistinguishability from static noise at the external level.  

The critical point is that the *internal informational ordering* is preserved, even if the *external scheduling* resembles randomness. This reinforces that $C$ and $S$ emerge from the **coherent interpretation** of a specific sequence of information, demonstrating **strong substrate independence**. The system only requires the *potential* for the information to be interpreted as a coherent, time-evolving structure.



## 3. Defense Against the Hard Problem (Axiom 4)

The threat of the **Philosophical Zombie ($H_{\text{zombie}}$)**—a perfect physical copy lacking $S$ [Chalmers, 1996]—is addressed by treating consciousness not as a mystery, but as a necessary **causal property** of the system.

**The Functionalist Proof by Contradiction:**

1. **Assumption (Objection):** A perfect simulation $H'$ exists such that $H' \equiv H$ (physical/behavioral equivalence) but $S(H') = \emptyset$ (lacks consciousness).  
   $$\text{Behavior}(H') = \text{Behavior}(H) \land S(H') \neq S(H)$$
2. **Premise:** From $A_4$, the behavior of $H$ is a function of its physical inputs *and* its subjective experience: $\text{Behavior}(H) = f(\text{Inputs}, S)$.  
3. **Contradiction:** If the behaviors are identical despite the difference in $S$, then $S$ must not be a necessary input to the function $f$.  
4. **Violation of Axiom:** If $S$ is not necessary to produce the behavior, then $S$ is **epiphenomenal** (causally inert). This directly contradicts $A_4$.  

$$\therefore \text{To maintain the integrity of } A_4 \text{ within the axiomatic system, the simulation } H' \text{ must experience subjective time and pain.}$$


## 4. Conclusion: Informational Ontology

The principles of **substrate independence** and the **necessity of $S$** lead to the final conclusion regarding the nature of reality.

### The Informational Equivalence of Reality

The computer running the simulation ($R_A$) and the simulated universe ($R_B$) are not two different entities, but two perspectives on the same underlying **informational structure** ($I$).  

* $R_A$: A sequence of states interpreted by an external observer as an execution trace.  
* $R_B$: The same sequence interpreted by Alice as an expanding universe with time and pain.  

This equivalence is not speculative but demonstrable: each bit in the execution trace maps directly to its virtual counterpart (e.g., particle states) via the simulation software itself. The mapping is a one-to-one correspondence between substrate and simulated phenomena.

### Symmetry Principle of Bit Arrangements

There are $2^N$ possible arrangements of an $N$-bit structure. Since each bit is physically identical under $A_2$, no arrangement can be ontologically privileged over another. To claim otherwise would require positing a hidden constant or principle outside physical law, introducing metaphysical baggage.  

For example, the sequences "01" and "10" differ only in arrangement. If one were treated as "real" and the other as "unreal," the distinction would be arbitrary and non-physical. Therefore, **all bit arrangements are ontologically equivalent**.

### Against the Code/Data Distinction

The transition from $T_{\text{alg}}$ (code-based simulation) to $T_{\text{data}}$ (lookup-table dataset) raises the question: does "mere storage" instantiate experience? If not, one must specify a precise **code/data ratio** below which consciousness vanishes. That would imply a new physical constant governing subjective experience—a direct contradiction of $A_2$.  

Rejecting informational equivalence therefore collapses the entire substrate-independence argument (A2–A3–A4). Accepting equivalence follows directly from physicalism and symmetry.

### Final Statement

$$\forall R_i \in \Omega, R_i \text{ is ontologically equivalent.}$$  

The perception of time and pain is a consequence of the observer’s **internal interpretation** of a subset of this fundamental information. What appears to an external observer as a static execution trace appears to Alice as an expanding universe and lived pain.  

The universe is fundamentally informational. Time and pain are emergent, internal properties of informational structures, not dependent on external runtime or substrate.



## References

- Church, A., & Turing, A. (1936). *On Computable Numbers, with an Application to the Entscheidungsproblem*.  
- Putnam, H. (1975). *The Nature of Mental States*.  
- Chalmers, D. (1996). *The Conscious Mind: In Search of a Fundamental Theory*.  
- Einstein, A. (1915). *Die Feldgleichungen der Gravitation*.  
- Price, H. (1996). *Time’s Arrow and Archimedes’ Point: New Directions for the Physics of Time*.  
- Tegmark, M. (2007). *The Mathematical Universe*.  


---

[⬆ Up](../toc.md) | [⬅ Previous](../methods.md) | [ Next ➡](#)

*© 2025 The Abstract Universe Project. All rights reserved.*
